}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
return(list(spl,segment,sent))
}
temp = getCom(input='之前用纯R写了Matrix67之前提到的无监督分词算法，感觉效率很慢……又照着最朴素的隐马试了一下无监督分词，效果很差很差……刚才写了一个R和@哈工大SCIR 的语言云的小接口，顿时感觉非常幸福！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
a[[1]]
names(a[[1]])
names(a[[1]])=NULL
a[[1]]
names(a[[1]])=a[[3]]
a[[1]]
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
a[[1]]
getRes = function(result)
{
subjects = xpathSApply(tmp,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(tmp,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
a[[1]]
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
getCom = function(input,mission='ws',user='hetong007@gmail.com:ypcOZA6a',pw='password')
{
addr = "http://api.ltp-cloud.com:8080"
uris = "/ltp_srv/ltp"
server = paste(addr,uris,sep='')
header = as.character(base64(paste(user,pw,sep=':')))
header = paste('Basic',header)
header = c('Authorization'=header)
data = 'x=n&c=utf-8&t=all'
data = paste(data,input,sep='&s=')
data = URLencode(data)
#getURL(server,httpHEAD=header)
ans = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
ans = rawToChar(ans)
ans
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt)
#tmp = htmlTreeParse(temp,useInternalNodes=T)
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(tmp,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(tmp,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(tmp)
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
getRes(return_value)
return_value = getCom(input='我爱北京天安门')
test = getRes(return_value)
test[[1]]
getCom = function(input,mission='ws',user='hetong007@gmail.com:ypcOZA6a',pw='password')
{
addr = "http://api.ltp-cloud.com:8080"
uris = "/ltp_srv/ltp"
server = paste(addr,uris,sep='')
header = as.character(base64(paste(user,pw,sep=':')))
header = paste('Basic',header)
header = c('Authorization'=header)
data = 'x=n&c=utf-8&t=all'
data = paste(data,input,sep='&s=')
data = URLencode(data)
#getURL(server,httpHEAD=header)
ans = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
ans = rawToChar(ans)
ans
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt)
#tmp = htmlTreeParse(temp,useInternalNodes=T)
getCom = function(input,mission='ws',user='hetong007@gmail.com:ypcOZA6a',pw='password')
{
addr = "http://api.ltp-cloud.com:8080"
uris = "/ltp_srv/ltp"
server = paste(addr,uris,sep='')
header = as.character(base64(paste(user,pw,sep=':')))
header = paste('Basic',header)
header = c('Authorization'=header)
data = 'x=n&c=utf-8&t=all'
data = paste(data,input,sep='&s=')
data = URLencode(data)
#getURL(server,httpHEAD=header)
ans = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
ans = rawToChar(ans)
return(ans)
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt)
#tmp = htmlTreeParse(temp,useInternalNodes=T)
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(tmp,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(tmp,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
return_value = getCom(input='我爱北京天安门')
test = getRes(return_value)
test[[1]]
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(result,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(result,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(result,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(result,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(result,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(result,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse='   ')
return(list(spl,segment,sent))
}
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
nchar(txt)
return_value = getCom(input=txt)
test = getRes(return_value)
test[[1]]
N = 10000000;
h = rep(0,N)
function pushDown(pos, n) {
while (2 * pos + 1 < n) {
j = 2 * pos + 1;
if (j + 1 < n && h[j + 1] > h[j])
j=j+1;
if (h[pos] >= h[j])
break;
t = h[pos];
h[pos] = h[j];
h[j] = t;
pos = j;
}
}
function main() {
start = proc.time();
for (i in 1:N) {
h[i] = i;
}
N = 10000000;
h = rep(0,N)
pushDown=function(pos, n) {
while (2 * pos + 1 < n) {
j = 2 * pos + 1;
if (j + 1 < n && h[j + 1] > h[j])
j=j+1;
if (h[pos] >= h[j])
break;
t = h[pos];
h[pos] = h[j];
h[j] = t;
pos = j;
}
}
main=function() {
start = proc.time();
for (i in 1:N) {
h[i] = i;
}
for (i in ((N+1)/2):1)
pushDown(i, N);
n = N;
while (n > 1) {
t = h[0];
h[0] = h[n - 1];
h[n - 1] = t;
n=n-1;
pushDown(0, n);
}
for (i in 1:N) {
if (h[i] != i) {
stop("h[i] != i");
}
}
show(paste("Done in " + (proc.time() - start)));
}
main();
N=10000
main()
install.packages("Rwordseg", repos = "http://R-Forge.R-project.org")
?xor
xor
xor(1,0)
xor(1,1)
xor
setwd('~/github/rLTP/')
require(devtools)
build()
install.packages('~/github/rLTP_0.1.tar.gz',type='source')
?ltp
ls()
ltp
require(ltp)
require(rLTP)
ltp
?ltp
a=ltp('美国的华莱士，比你们不知高到哪里去了。我和他谈笑风生!')
as.data.frame(a)
a=ltp(file='~/github/WordSplit/wuxia/越女剑.txt')
a
a[c(3,5,6,10)]
a[c(3,5,6,10,100)]
a=ltp(file='~/github/WordSplit/wuxia/白马啸西风.txt')
a
a=ltp(file='~/github/WordSplit/wuxia/碧血剑.txt')
a
check()
check()
a=ltp('美国的华莱士，比你们不知高到哪里去了。我和他谈笑风生!')
check()
document()
build()
?install_github
install_github(repo='rLTP',username='hetong007')
require(devtools)
install_github('rLTP','hetong007')
require(rLTP)
?ltp
require(ISwR)
isntall.packages('ISwR')
install.packages('ISwR')
require(devtools)
setwd('~/github/rLTP')
document()
load_all()
rm(list=ls())
ls()
require(rLTP)
?ltp
ltp
ls()
load_all()
document
document()
