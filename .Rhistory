't' = mission)
ans = rawToChar(ans)
ans
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt,user='hetong007@gmail.com:ypcOZA6a')
#tmp = htmlTreeParse(temp,useInternalNodes=T)
temp = getCom(input='我爱北京天安门',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
a
temp = getCom(input='之前用纯R写了Matrix67之前提到的无监督分词算法，感觉效率很慢……又照着最朴素的隐马试了一下无监督分词，效果很差很差……刚才写了一个R和@哈工大SCIR 的语言云的小接口，顿时感觉非常幸福！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
a
getRes = function(result)
{
subjects = xpathSApply(tmp,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(tmp,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
return(list(segment,sent))
}
temp = getCom(input='之前用纯R写了Matrix67之前提到的无监督分词算法，感觉效率很慢……又照着最朴素的隐马试了一下无监督分词，效果很差很差……刚才写了一个R和@哈工大SCIR 的语言云的小接口，顿时感觉非常幸福！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
a
getRes = function(result)
{
subjects = xpathSApply(tmp,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(tmp,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
return(list(spl,segment,sent))
}
temp = getCom(input='之前用纯R写了Matrix67之前提到的无监督分词算法，感觉效率很慢……又照着最朴素的隐马试了一下无监督分词，效果很差很差……刚才写了一个R和@哈工大SCIR 的语言云的小接口，顿时感觉非常幸福！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
a[[1]]
names(a[[1]])
names(a[[1]])=NULL
a[[1]]
names(a[[1]])=a[[3]]
a[[1]]
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
a[[1]]
getRes = function(result)
{
subjects = xpathSApply(tmp,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(tmp,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
a[[1]]
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
getCom = function(input,mission='ws',user='hetong007@gmail.com:ypcOZA6a',pw='password')
{
addr = "http://api.ltp-cloud.com:8080"
uris = "/ltp_srv/ltp"
server = paste(addr,uris,sep='')
header = as.character(base64(paste(user,pw,sep=':')))
header = paste('Basic',header)
header = c('Authorization'=header)
data = 'x=n&c=utf-8&t=all'
data = paste(data,input,sep='&s=')
data = URLencode(data)
#getURL(server,httpHEAD=header)
ans = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
ans = rawToChar(ans)
ans
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt)
#tmp = htmlTreeParse(temp,useInternalNodes=T)
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(tmp,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(tmp,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(tmp)
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
getRes(return_value)
return_value = getCom(input='我爱北京天安门')
test = getRes(return_value)
test[[1]]
getCom = function(input,mission='ws',user='hetong007@gmail.com:ypcOZA6a',pw='password')
{
addr = "http://api.ltp-cloud.com:8080"
uris = "/ltp_srv/ltp"
server = paste(addr,uris,sep='')
header = as.character(base64(paste(user,pw,sep=':')))
header = paste('Basic',header)
header = c('Authorization'=header)
data = 'x=n&c=utf-8&t=all'
data = paste(data,input,sep='&s=')
data = URLencode(data)
#getURL(server,httpHEAD=header)
ans = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
ans = rawToChar(ans)
ans
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt)
#tmp = htmlTreeParse(temp,useInternalNodes=T)
getCom = function(input,mission='ws',user='hetong007@gmail.com:ypcOZA6a',pw='password')
{
addr = "http://api.ltp-cloud.com:8080"
uris = "/ltp_srv/ltp"
server = paste(addr,uris,sep='')
header = as.character(base64(paste(user,pw,sep=':')))
header = paste('Basic',header)
header = c('Authorization'=header)
data = 'x=n&c=utf-8&t=all'
data = paste(data,input,sep='&s=')
data = URLencode(data)
#getURL(server,httpHEAD=header)
ans = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
ans = rawToChar(ans)
return(ans)
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt)
#tmp = htmlTreeParse(temp,useInternalNodes=T)
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(tmp,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(tmp,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
return_value = getCom(input='我爱北京天安门')
test = getRes(return_value)
test[[1]]
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(result,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(result,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(result,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(result,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(result,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(result,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse='   ')
return(list(spl,segment,sent))
}
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
nchar(txt)
return_value = getCom(input=txt)
test = getRes(return_value)
test[[1]]
setwd('~/github/rLTP/')
require(devtools)
load_all()
load_all()
