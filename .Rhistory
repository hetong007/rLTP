nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
a[[1]]
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
getCom = function(input,mission='ws',user='hetong007@gmail.com:ypcOZA6a',pw='password')
{
addr = "http://api.ltp-cloud.com:8080"
uris = "/ltp_srv/ltp"
server = paste(addr,uris,sep='')
header = as.character(base64(paste(user,pw,sep=':')))
header = paste('Basic',header)
header = c('Authorization'=header)
data = 'x=n&c=utf-8&t=all'
data = paste(data,input,sep='&s=')
data = URLencode(data)
#getURL(server,httpHEAD=header)
ans = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
ans = rawToChar(ans)
ans
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt)
#tmp = htmlTreeParse(temp,useInternalNodes=T)
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(tmp,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(tmp,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(tmp)
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
getRes(return_value)
return_value = getCom(input='我爱北京天安门')
test = getRes(return_value)
test[[1]]
getCom = function(input,mission='ws',user='hetong007@gmail.com:ypcOZA6a',pw='password')
{
addr = "http://api.ltp-cloud.com:8080"
uris = "/ltp_srv/ltp"
server = paste(addr,uris,sep='')
header = as.character(base64(paste(user,pw,sep=':')))
header = paste('Basic',header)
header = c('Authorization'=header)
data = 'x=n&c=utf-8&t=all'
data = paste(data,input,sep='&s=')
data = URLencode(data)
#getURL(server,httpHEAD=header)
ans = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
ans = rawToChar(ans)
ans
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt)
#tmp = htmlTreeParse(temp,useInternalNodes=T)
getCom = function(input,mission='ws',user='hetong007@gmail.com:ypcOZA6a',pw='password')
{
addr = "http://api.ltp-cloud.com:8080"
uris = "/ltp_srv/ltp"
server = paste(addr,uris,sep='')
header = as.character(base64(paste(user,pw,sep=':')))
header = paste('Basic',header)
header = c('Authorization'=header)
data = 'x=n&c=utf-8&t=all'
data = paste(data,input,sep='&s=')
data = URLencode(data)
#getURL(server,httpHEAD=header)
ans = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
ans = rawToChar(ans)
return(ans)
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt)
#tmp = htmlTreeParse(temp,useInternalNodes=T)
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(tmp,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(tmp,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
return_value = getCom(input='我爱北京天安门')
test = getRes(return_value)
test[[1]]
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(result,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(result,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(result,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(result,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(result,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(result,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse='   ')
return(list(spl,segment,sent))
}
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
nchar(txt)
return_value = getCom(input=txt)
test = getRes(return_value)
test[[1]]
N = 10000000;
h = rep(0,N)
function pushDown(pos, n) {
while (2 * pos + 1 < n) {
j = 2 * pos + 1;
if (j + 1 < n && h[j + 1] > h[j])
j=j+1;
if (h[pos] >= h[j])
break;
t = h[pos];
h[pos] = h[j];
h[j] = t;
pos = j;
}
}
function main() {
start = proc.time();
for (i in 1:N) {
h[i] = i;
}
N = 10000000;
h = rep(0,N)
pushDown=function(pos, n) {
while (2 * pos + 1 < n) {
j = 2 * pos + 1;
if (j + 1 < n && h[j + 1] > h[j])
j=j+1;
if (h[pos] >= h[j])
break;
t = h[pos];
h[pos] = h[j];
h[j] = t;
pos = j;
}
}
main=function() {
start = proc.time();
for (i in 1:N) {
h[i] = i;
}
for (i in ((N+1)/2):1)
pushDown(i, N);
n = N;
while (n > 1) {
t = h[0];
h[0] = h[n - 1];
h[n - 1] = t;
n=n-1;
pushDown(0, n);
}
for (i in 1:N) {
if (h[i] != i) {
stop("h[i] != i");
}
}
show(paste("Done in " + (proc.time() - start)));
}
main();
N=10000
main()
install.packages("Rwordseg", repos = "http://R-Forge.R-project.org")
?xor
xor
xor(1,0)
xor(1,1)
xor
setwd("~/github/rLTP/")
require(devtools)
load_all()
?vector
source('R/doc.R')
debug(ltp)
ltp(input='~/github/WordSplit/wuxia/天龙八部.txt')
length(inputs)
ltp(file='~/github/WordSplit/wuxia/天龙八部.txt')
n+1
ltp(file='~/github/WordSplit/wuxia/天龙八部.txt')
nchar(inputs[i])
mission
ID
ltp(file='~/github/WordSplit/wuxia/天龙八部.txt')
debug(commLTP)
ltp(file='~/github/WordSplit/wuxia/天龙八部.txt')
nchar(input)
object.size(input)
?xmlToList
class(r[[2]])
?htmlTreeParse
result = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
result = rawToChar(result)
result = xmlTreeParse(result,useInternalNodes=T)
r = xmlRoot(result)
r = r[[1]][[1]]
missions = xmlAttrs(r[[1]])=='y'
ind = match(names(missions),
c("sent","word","pos","ne","parser","wsd","srl"))
missions = missions[ind]
if (!missions[1])
{
cat('Mission Unfinished!\n')
return(doc(tags=missions));
}
para_xml = xmlToList(r[[2]])#doc tag
tmp=xmlTreeParse(result,useInternalNodes=T)
class(tmp)
r = xmlRoot(tmp)
class(r)
r
r = r[[1]][[1]]
missions = xmlAttrs(r[[1]])=='y'
class(r[[1]])
r = xmlRoot(tmp)
length(r)
str(r)
r[[1]]
r[[2]]
tr=xmlRoot(tmp)
identical(tr,r)
tr[[1]]
r[[1]]
r[[1]][[1]]
class(r)
class(tr)
length(tr)
length(r)
r=xmlToList(r)
tr=xmlToList(tr)
names(tr)
names(r)
names(r[[1]])
names(r[[1]][[1]])
identical(tr,r[[1]][[1]])
load_all()
source('R/doc.R')
ltp(file='~/github/WordSplit/wuxia/天龙八部.txt')
debug(ltp)
ltp(file='~/github/WordSplit/wuxia/天龙八部.txt')
debug(parseLTP)
length(para_xml)
length(sent_xml)
n+1
undebug(parseLTP)
undebug(ltp)
ltp(file='~/github/WordSplit/wuxia/越女剑.txt')
a=ltp(file='~/github/WordSplit/wuxia/越女剑.txt')
load_all()
a=ltp(file='~/github/WordSplit/wuxia/天龙八部.txt')
tmp=readLines('~/github/WordSplit/wuxia/天龙八部.txt')
nchar(tmp)
tmp=toUTF8(tmp)
nchar(tmp)
sum(nchar(tmp))
