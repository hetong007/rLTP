if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
a[[1]]
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！',mission='dp',user='hetong007@gmail.com:ypcOZA6a')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
getCom = function(input,mission='ws',user='hetong007@gmail.com:ypcOZA6a',pw='password')
{
addr = "http://api.ltp-cloud.com:8080"
uris = "/ltp_srv/ltp"
server = paste(addr,uris,sep='')
header = as.character(base64(paste(user,pw,sep=':')))
header = paste('Basic',header)
header = c('Authorization'=header)
data = 'x=n&c=utf-8&t=all'
data = paste(data,input,sep='&s=')
data = URLencode(data)
#getURL(server,httpHEAD=header)
ans = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
ans = rawToChar(ans)
ans
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt)
#tmp = htmlTreeParse(temp,useInternalNodes=T)
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
tmp = htmlTreeParse(temp,useInternalNodes=T)
a = getRes(tmp)
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(tmp,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(tmp,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
temp = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(tmp)
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成这样，好像云端的LTP有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
getRes(return_value)
return_value = getCom(input='我爱北京天安门')
test = getRes(return_value)
test[[1]]
getCom = function(input,mission='ws',user='hetong007@gmail.com:ypcOZA6a',pw='password')
{
addr = "http://api.ltp-cloud.com:8080"
uris = "/ltp_srv/ltp"
server = paste(addr,uris,sep='')
header = as.character(base64(paste(user,pw,sep=':')))
header = paste('Basic',header)
header = c('Authorization'=header)
data = 'x=n&c=utf-8&t=all'
data = paste(data,input,sep='&s=')
data = URLencode(data)
#getURL(server,httpHEAD=header)
ans = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
ans = rawToChar(ans)
ans
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt)
#tmp = htmlTreeParse(temp,useInternalNodes=T)
getCom = function(input,mission='ws',user='hetong007@gmail.com:ypcOZA6a',pw='password')
{
addr = "http://api.ltp-cloud.com:8080"
uris = "/ltp_srv/ltp"
server = paste(addr,uris,sep='')
header = as.character(base64(paste(user,pw,sep=':')))
header = paste('Basic',header)
header = c('Authorization'=header)
data = 'x=n&c=utf-8&t=all'
data = paste(data,input,sep='&s=')
data = URLencode(data)
#getURL(server,httpHEAD=header)
ans = postForm(uri = server,
.opts = curlOptions(httpHEAD=header),
style = "post",
'x' = 'n',
's' = input,
'c' = 'utf-8',
't' = mission)
ans = rawToChar(ans)
return(ans)
}
#require(tmcn)
#require(RCurl)
#require(XML)
#txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
#txt=toUTF8(txt)
#txt=gsub('\\s+','',txt)
#txt=paste(txt,collapse='')
#temp = getCom(txt)
#tmp = htmlTreeParse(temp,useInternalNodes=T)
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(tmp,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(tmp,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(tmp,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
return_value = getCom(input='我爱北京天安门')
test = getRes(return_value)
test[[1]]
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(result,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(result,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(result,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse=' | ')
return(list(spl,segment,sent))
}
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
getRes = function(result)
{
result = htmlTreeParse(result,useInternalNodes=T)
subjects = xpathSApply(result,'//note',xmlAttrs)[,1]
subjects = subjects=='y'
if (!subjects['sent'])
{
cat('Unfinished!\n')
return(NULL);
}
sent = xpathSApply(result,"//sent",xmlAttrs)
n = length(sent)
sent = sent[(1:n)%%2==0]
n = length(sent)
if (!subjects['word'])
{
cat('Segmentation is Unfinished, Returning Sentences.\n')
return(sent)
}
nms = 'cont'
if (subjects['pos'])
nms = c(nms,'pos')
if (subjects['ne'])
nms = c(nms,'ne')
if (subjects['parser'])
nms = c(nms,'parent','relate')
if (subjects['wsd'])
nms = c(nms,'wsd','wsdexp')
#Not considering srl yet!
segment = NULL
for (i in 1:n)
{
command = paste('//sent[@id=',i-1,']/word',sep='\'')
tdat = xpathSApply(result,command,xmlAttrs)
nm = rownames(tdat)
ind = match(nms,nm,0)
ind = ind[ind!=0]
tdat = t(tdat[c(1,ind),,drop=FALSE])
tdat = cbind(i,tdat)
segment[[i]] = tdat
}
segment = do.call(rbind,segment)
segment = as.data.frame(segment)
nms = names(segment)
names(segment) = c('sent_id',nms[-1])
#spl = tapply(segment$cont,segment$sent_id,paste,collapse=' | ')
spl = paste(segment$cont,collapse='   ')
return(list(spl,segment,sent))
}
return_value = getCom(input='其实还有很多bug没改掉，不过我自己测试的效果长成下面这样。语言云服务有最大文件上传限制，但是十万个字以内应该是没有问题的（比如金庸的短篇越女剑就可以一次性分析完，但是天龙八部却不行……），实在不行可以切分一下分块来传。非常方便，赞一下@哈工大SCIR ！')
test = getRes(return_value)
test[[1]]
nchar(txt)
return_value = getCom(input=txt)
test = getRes(return_value)
test[[1]]
N = 10000000;
h = rep(0,N)
function pushDown(pos, n) {
while (2 * pos + 1 < n) {
j = 2 * pos + 1;
if (j + 1 < n && h[j + 1] > h[j])
j=j+1;
if (h[pos] >= h[j])
break;
t = h[pos];
h[pos] = h[j];
h[j] = t;
pos = j;
}
}
function main() {
start = proc.time();
for (i in 1:N) {
h[i] = i;
}
N = 10000000;
h = rep(0,N)
pushDown=function(pos, n) {
while (2 * pos + 1 < n) {
j = 2 * pos + 1;
if (j + 1 < n && h[j + 1] > h[j])
j=j+1;
if (h[pos] >= h[j])
break;
t = h[pos];
h[pos] = h[j];
h[j] = t;
pos = j;
}
}
main=function() {
start = proc.time();
for (i in 1:N) {
h[i] = i;
}
for (i in ((N+1)/2):1)
pushDown(i, N);
n = N;
while (n > 1) {
t = h[0];
h[0] = h[n - 1];
h[n - 1] = t;
n=n-1;
pushDown(0, n);
}
for (i in 1:N) {
if (h[i] != i) {
stop("h[i] != i");
}
}
show(paste("Done in " + (proc.time() - start)));
}
main();
N=10000
main()
install.packages("Rwordseg", repos = "http://R-Forge.R-project.org")
?xor
xor
xor(1,0)
xor(1,1)
xor
install.packages('~/github/rLTP_0.1.tar.gz', type='source')
require(rLTP)
a=ltp('美国的华莱士，比你们不知高到哪里去了。我和他谈笑风生!')
a
length(a)
tags(a)
a[2]
sents(a)
as.data.frame(a)
?detach
detach(package:rLTP)
ltp
getwd()
setwd('~/github/rLTP')
require(devtools)
load_all()
load_all()
a=c(1,3,5)
b=c(2,4,6)
a[1:2]:b[1:2]
':'
?':'
':'(a=a,b=b)
?seq
lapply(c(1,2),function(x)a[x]:b[x])
sapply(c(1,2),function(x)a[x]:b[x])
lapply(c(1,2),function(x)a[x]:b[x])
unlist(lapply(c(1,2),function(x)a[x]:b[x]))
unique(unlist(lapply(c(1,2),function(x)a[x]:b[x])))
load_all()
load_all()
load_all()
load_all()
document()
document()
document()
document()
document()
document()
require(Matrix)
?dgCMatrix-class
load_all()
document()
load_all()
load_all()
document()
load_all()
document()
load_all()
load_all()
document()
build()
install.packages('~/github/rLTP_0.1.tar.gz',type='source')
require(rLTP)
?ltp
?install.packages
install.packages('~/github/rLTP_0.1.tar.gz',repo='source')
install.packages('~/github/rLTP_0.1.tar.gz',type='source')
require(rLTP)
?ltp
ltp
a=ltp('美国的华莱士，比你们不知高到哪里去了。我和他谈笑风生!')
str(a)
a@tags
a@sents
a[1:3]
a[c(2,1)]
class(a)
detach(package:rLTP)
load_all()
?ltp
load_all()
document()
load_all()
document()
load_all()
a[c(2,1)]
load_all()
document()
load_all()
document()
load_all()
document()
load_all()
load_all()
document()
a=ltp('美国的华莱士，比你们不知高到哪里去了。我和他谈笑风生!')
a
length(a)
a[2]
as.data.frame(a)
